{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning in Julia, JuliaCon2020"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A workshop introducing the machine learning toolbox\n",
    "[MLJ](https://alan-turing-institute.github.io/MLJ.jl/stable/)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following instantiates a package environment and pre-loads some\n",
    "packages, to avoid delays later on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The package environment has been created using **Julia 1.6** and may not\n",
    "instantiate properly for other Julia versions."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "VERSION"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "DIR = @__DIR__\n",
    "include(joinpath(DIR, \"setup.jl\"))\n",
    "color_off()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General resources"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [List of methods introduced in this tutorial](methods.md)\n",
    "- [MLJ Cheatsheet](https://alan-turing-institute.github.io/MLJ.jl/dev/mlj_cheatsheet/)\n",
    "- [Common MLJ Workflows](https://alan-turing-institute.github.io/MLJ.jl/dev/common_mlj_workflows/)\n",
    "- [MLJ manual](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n",
    "- [Data Science Tutorials in Julia](https://juliaai.github.io/DataScienceTutorials.jl/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Contents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [Part 1 - Data Representation](#part-1-data-representation)\n",
    "- [Part 2 - Selecting, Training and Evaluating Models](#part-2-selecting-training-and-evaluating-models)\n",
    "- [Part 3 - Transformers and Pipelines](#part-3-transformers-and-pipelines)\n",
    "- [Part 4 - Tuning Hyper-parameters](#part-4-tuning-hyper-parameters)\n",
    "- [Part 5 - Advanced model composition](#part-5-advanced-model-composition)\n",
    "- [Solutions to Exercises](#solutions-to-exercises)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part-1-data-representation'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1 - Data Representation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Learn how MLJ specifies it's data requirements using \"scientific\" types\n",
    "> 2. Understand the options for representing tabular data\n",
    "> 3. Learn how to inspect and fix the representation of data to meet MLJ requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scientific types"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To help you focus on the intended *purpose* or *interpretation* of\n",
    "data, MLJ models specify data requirements using *scientific types*,\n",
    "instead of machine types. An example of a scientific type is\n",
    "`OrderedFactor`. The other basic \"scalar\" scientific types are\n",
    "illustrated below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](assets/scitypes.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A scientific type is an ordinary Julia type (so it can be used for\n",
    "method dispatch, for example) but it usually has no instances. The\n",
    "`scitype` function is used to articulate MLJ's convention about how\n",
    "different machine types will be interpreted by MLJ models:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "scitype(3.141)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "time = [2.3, 4.5, 4.2, 1.8, 7.1]\n",
    "scitype(time)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fix data which MLJ is interpreting incorrectly, we use the\n",
    "`coerce` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "height = [185, 153, 163, 114, 180]\n",
    "scitype(height)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "height = coerce(height, Continuous)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's an example of data we would want interpreted as\n",
    "`OrderedFactor` but isn't:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "exam_mark = [\"rotten\", \"great\", \"bla\",  missing, \"great\"]\n",
    "scitype(exam_mark)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "exam_mark = coerce(exam_mark, OrderedFactor)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "levels(exam_mark)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `levels!` to put the classes in the right order:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "levels!(exam_mark, [\"rotten\", \"bla\", \"great\"])\n",
    "exam_mark[1] < exam_mark[2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "When sub-sampling, no levels are lost:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "levels(exam_mark[1:2])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note on binary data.** There is no separate scientific type for\n",
    "binary data. Binary data is `OrderedFactor{2}` or\n",
    "`Multiclass{2}`. If a binary measure like `truepositive` is a\n",
    "applied to `OrderedFactor{2}` then the \"positive\" class is assumed\n",
    "to appear *second* in the ordering. If such a measure is applied to\n",
    "`Multiclass{2}` data, a warning is issued. A single `OrderedFactor`\n",
    "can be coerced to a single `Continuous` variable, for models that\n",
    "require this, while a `Multiclass` variable can only be one-hot\n",
    "encoded."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Two-dimensional data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whenever it makes sense, MLJ Models generally expect two-dimensional\n",
    "data to be *tabular*. All the tabular formats implementing the\n",
    "[Tables.jl API](https://juliadata.github.io/Tables.jl/stable/) (see\n",
    "this\n",
    "[list](https://github.com/JuliaData/Tables.jl/blob/master/INTEGRATIONS.md))\n",
    "have a scientific type of `Table` and can be used with such models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Probably the simplest example of a table is the julia native *column\n",
    "table*, which is just a named tuple of equal-length vectors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "column_table = (h=height, e=exam_mark, t=time)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(column_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the `Table{K}` type parameter `K` encodes the scientific\n",
    "types of the columns. (This is useful when comparing table scitypes\n",
    "with `<:`). To inspect the individual column scitypes, we use the\n",
    "`schema` method instead:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(column_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are five other examples of tables:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dict_table = Dict(:h => height, :e => exam_mark, :t => time)\n",
    "schema(dict_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(To control column order here, instead use `LittleDict` from\n",
    "OrderedCollections.jl.)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "row_table = [(a=1, b=3.4),\n",
    "             (a=2, b=4.5),\n",
    "             (a=3, b=5.6)]\n",
    "schema(row_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import DataFrames\n",
    "df = DataFrames.DataFrame(column_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(df) == schema(column_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CSV\n",
    "file = CSV.File(joinpath(DIR, \"data\", \"horse.csv\"));\n",
    "schema(file) # (triggers a file read)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most MLJ models do not accept matrix in lieu of a table, but you can\n",
    "wrap a matrix as a table:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "matrix_table = MLJ.table(rand(2,3))\n",
    "schema(matrix_table)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The matrix is *not* copied, only wrapped. Some models may perform\n",
    "better if one wraps the adjoint of the transpose - see\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Observations-correspond-to-rows,-not-columns)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Manipulating tabular data.** In this workshop we assume\n",
    "familiarity with some kind of tabular data container (although it is\n",
    "possible, in principle, to carry out the exercises without this.)\n",
    "For a quick start introduction to `DataFrames`, see [this\n",
    "tutorial](https://juliaai.github.io/DataScienceTutorials.jl/data/dataframe/)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fixing scientific types in tabular data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To show how we can correct the scientific types of data in tables,\n",
    "we introduce a cleaned up version of the UCI Horse Colic Data Set\n",
    "(the cleaning work-flow is described\n",
    "[here](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/horse/#dealing_with_missing_values))."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CSV\n",
    "file = CSV.File(joinpath(DIR, \"data\", \"horse.csv\"));\n",
    "horse = DataFrames.DataFrame(file); # convert to data frame without copying columns\n",
    "first(horse, 4)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [the UCI\n",
    "docs](http://archive.ics.uci.edu/ml/datasets/Horse+Colic) we can\n",
    "surmise how each variable ought to be interpreted (a step in our\n",
    "work-flow that cannot reliably be left to the computer):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "variable                    | scientific type (interpretation)\n",
    "----------------------------|-----------------------------------\n",
    "`:surgery`                  | Multiclass\n",
    "`:age`                      | Multiclass\n",
    "`:rectal_temperature`       | Continuous\n",
    "`:pulse`                    | Continuous\n",
    "`:respiratory_rate`         | Continuous\n",
    "`:temperature_extremities`  | OrderedFactor\n",
    "`:mucous_membranes`         | Multiclass\n",
    "`:capillary_refill_time`    | Multiclass\n",
    "`:pain`                     | OrderedFactor\n",
    "`:peristalsis`              | OrderedFactor\n",
    "`:abdominal_distension`     | OrderedFactor\n",
    "`:packed_cell_volume`       | Continuous\n",
    "`:total_protein`            | Continuous\n",
    "`:outcome`                  | Multiclass\n",
    "`:surgical_lesion`          | OrderedFactor\n",
    "`:cp_data`                  | Multiclass"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how MLJ will actually interpret the data, as it is\n",
    "currently encoded:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a first correction step, we can get MLJ to \"guess\" the\n",
    "appropriate fix, using the `autotype` method:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "autotype(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, this is not perfect, but a step in the right direction, which\n",
    "we implement like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(horse, autotype(horse));\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "All remaining `Count` data should be `Continuous`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(horse, Count => Continuous);\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll correct the remaining truant entries manually:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(horse,\n",
    "        :surgery               => Multiclass,\n",
    "        :age                   => Multiclass,\n",
    "        :mucous_membranes      => Multiclass,\n",
    "        :capillary_refill_time => Multiclass,\n",
    "        :outcome               => Multiclass,\n",
    "        :cp_data               => Multiclass);\n",
    "schema(horse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 1\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [A preview of data type specification in\n",
    "  MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#A-preview-of-data-type-specification-in-MLJ-1)\n",
    "   - [Data containers and scientific types](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Data-containers-and-scientific-types-1)\n",
    "   - [Working with Categorical Data](https://alan-turing-institute.github.io/MLJ.jl/dev/working_with_categorical_data/)\n",
    "- [Summary](https://juliaai.github.io/ScientificTypes.jl/dev/#Summary-of-the-default-convention) of the MLJ convention for representing scientific types\n",
    "- [ScientificTypes.jl](https://juliaai.github.io/ScientificTypes.jl/dev/)\n",
    "- From Data Science Tutorials:\n",
    "    - [Data interpretation: Scientific Types](https://juliaai.github.io/DataScienceTutorials.jl/data/scitype/)\n",
    "    - [Horse colic data](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/horse/)\n",
    "- [UCI Horse Colic Data Set](http://archive.ics.uci.edu/ml/datasets/Horse+Colic)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try to guess how each code snippet below will evaluate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(42)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "questions = [\"who\", \"why\", \"what\", \"when\"]\n",
    "scitype(questions)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "elscitype(questions)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "t = (3.141, 42, \"how\")\n",
    "scitype(t)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = rand(2, 3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "elscitype(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SparseArrays\n",
    "Asparse = sparse(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(Asparse)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CategoricalArrays\n",
    "C1 = categorical(A)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(C1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "elscitype(C1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "C2 = categorical(A, ordered=true)\n",
    "scitype(C2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "v = [1, 2, missing, 4]\n",
    "scitype(v)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "elscitype(v)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(v[1:2])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Can you guess at the general behavior of\n",
    "`scitype` with respect to tuples, abstract arrays and missing\n",
    "values? The answers are\n",
    "[here](https://github.com/juliaai/ScientificTypesBase.jl#2-the-scitype-and-scitype-methods)\n",
    "(ignore \"Property 1\")."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coerce the following vector to make MLJ recognize it as a vector of\n",
    "ordered factors (with an appropriate ordering):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "quality = [\"good\", \"poor\", \"poor\", \"excellent\", missing, \"good\", \"excellent\"]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3 (fixing scitypes in a table)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fix the scitypes for the [House Prices in King\n",
    "County](https://mlr3gallery.mlr-org.com/posts/2020-01-30-house-prices-in-king-county/)\n",
    "dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "file = CSV.File(joinpath(DIR, \"data\", \"house.csv\"));\n",
    "house = DataFrames.DataFrame(file); # convert to data frame without copying columns\n",
    "first(house, 4)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Two features in the original data set have been deemed uninformative\n",
    "and dropped, namely `:id` and `:date`. The original feature\n",
    "`:yr_renovated` has been replaced by the `Bool` feature `is_renovated`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part-2-selecting-training-and-evaluating-models'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2 - Selecting, Training and Evaluating Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Search MLJ's database of model metadata to identify model candidates for a supervised learning task.\n",
    "> 2. Evaluate the performance of a model on a holdout set using basic `fit!`/`predict` work-flow.\n",
    "> 3. Inspect the outcomes of training and save these to a file.\n",
    "> 3. Evaluate performance using other resampling strategies, such as cross-validation, in one line, using `evaluate!`\n",
    "> 4. Plot a \"learning curve\", to inspect performance as a function of some model hyper-parameter, such as an iteration parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"Hello World!\" of machine learning is to classify Fisher's\n",
    "famous iris data set. This time, we'll grab the data from\n",
    "[OpenML](https://www.openml.org):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "OpenML.describe_dataset(61)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "iris = OpenML.load(61); # a row table\n",
    "iris = DataFrames.DataFrame(iris);\n",
    "first(iris, 4)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Main goal.** To build and evaluate models for predicting the\n",
    "`:class` variable, given the four remaining measurement variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1. Inspect and fix scientific types"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(iris)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, `Missing` is appearing in the element type, despite\n",
    "the fact there are no missing values (see this\n",
    "[issue](https://github.com/JuliaAI/OpenML.jl/issues/10)). To do this\n",
    "we have to explicilty tighten the types:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(iris,\n",
    "        Union{Missing,Continuous}=>Continuous,\n",
    "        Union{Missing,Multiclass}=>Multiclass,\n",
    "        tight=true)\n",
    "schema(iris)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2. Split data into input and target parts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's how we split the data into target and input features, which\n",
    "is needed for MLJ supervised models. We randomize the data at the\n",
    "same time:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(iris, ==(:class), name->true; rng=123);\n",
    "scitype(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's one way to access the documentation (at the REPL, `?unpack`\n",
    "also works):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@doc unpack"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On searching for a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's how to see *all* models (not immediately useful):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "all_models = models()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each entry contains metadata for a model whose defining code is not yet loaded:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "meta = all_models[3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "targetscitype = meta.target_scitype"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(y) <: targetscitype"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "So this model won't do. Let's  find all pure julia classifiers:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "filter_julia_classifiers(meta) =\n",
    "    AbstractVector{Finite} <: meta.target_scitype &&\n",
    "    meta.is_pure_julia\n",
    "\n",
    "models(filter_julia_classifiers)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all models with \"Classifier\" in `name` (or `docstring`):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(\"Classifier\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all (supervised) models that match my data!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(matching(X, y))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3. Select and instantiate a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To load the code defining a new model type we use the `@load` macro:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other ways to load model code are described\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/loading_model_code/#Loading-Model-Code)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll instantiate this type with default values for the\n",
    "hyperparameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = NeuralNetworkClassifier()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "info(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a *model* is just a struct containing hyper-parameters, and\n",
    "that's all. A model does not store *learned* parameters. Models are\n",
    "mutable:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model.epochs = 12"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And all models have a key-word constructor that works once `@load`\n",
    "has been performed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NeuralNetworkClassifier(epochs=12) == model"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On fitting, predicting, and inspecting models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a model and training/validation data are typically bound\n",
    "together in a machine:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(model, X, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A machine stores *learned* parameters, among other things. We'll\n",
    "train this machine on 70% of the data and evaluate on a 30% holdout\n",
    "set. Let's start by dividing all row indices into `train` and `test`\n",
    "subsets:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can `fit!`..."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "... and `predict`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "yhat = predict(mach, rows=test);  # or `predict(mach, Xnew)`\n",
    "yhat[1:3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll have more to say on the form of this prediction shortly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After training, one can inspect the learned parameters:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Everything else the user might be interested in is accessed from the\n",
    "training *report*:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "report(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You save a machine like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "MLJ.save(\"neural_net.jlso\", mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And retrieve it like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach2 = machine(\"neural_net.jlso\")\n",
    "yhat = predict(mach2, X);\n",
    "yhat[1:3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to fit a retrieved model, you will need to bind some data to it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach3 = machine(\"neural_net.jlso\", X, y)\n",
    "fit!(mach3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Machines remember the last set of hyper-parameters used during fit,\n",
    "which, in the case of iterative models, allows for a warm restart of\n",
    "computations in the case that only the iteration parameter is\n",
    "increased:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model.epochs = model.epochs + 4\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this particular model we can also increase `:learning_rate`\n",
    "without triggering a cold restart:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model.epochs = model.epochs + 4\n",
    "model.optimiser.eta = 10*model.optimiser.eta\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, change any other parameter and training will restart from\n",
    "scratch:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model.lambda = 0.001\n",
    "fit!(mach, rows=train, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterative models that implement warm-restart for training can be\n",
    "controlled externally (eg, using an out-of-sample stopping\n",
    "criterion). See\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/)\n",
    "for details."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train silently for a total of 50 epochs, and look at a\n",
    "prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model.epochs = 50\n",
    "fit!(mach, rows=train)\n",
    "yhat = predict(mach, X[test,:]); # or predict(mach, rows=test)\n",
    "yhat[1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's going on here?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "info(model).prediction_type"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Important**:\n",
    "- In MLJ, a model that can predict probabilities (and not just point values) will do so by default.\n",
    "- For most probabilistic predictors, the predicted object is a `Distributions.Distribution` object, supporting the `Distributions.jl` [API](https://juliastats.org/Distributions.jl/latest/extends/#Create-a-Distribution-1) for such objects. In particular, the methods `rand`,  `pdf`, `logpdf`, `mode`, `median` and `mean` will apply, where appropriate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, to obtain the probability of \"Iris-virginica\" in the first test\n",
    "prediction, we do"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pdf(yhat[1], \"Iris-virginica\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the most likely observation, we do"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mode(yhat[1])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "These can be broadcast over multiple predictions in the usual way:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "broadcast(pdf, yhat[1:4], \"Iris-versicolor\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mode.(yhat[1:4])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, alternatively, you can use the `predict_mode` operation instead\n",
    "of `predict`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "predict_mode(mach, X[test,:])[1:4] # or predict_mode(mach, rows=test)[1:4]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a more conventional matrix of probabilities you can do this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "L = levels(y)\n",
    "pdf(yhat, L)[1:4, :]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, in a typical MLJ work-flow, this is not as useful as you\n",
    "might imagine. In particular, all probabilistic performance measures\n",
    "in MLJ expect distribution objects in their first slot:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cross_entropy(yhat, y[test]) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To apply a deterministic measure, we first need to obtain point-estimates:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(yhat), y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We note in passing that there is also a search tool for measures\n",
    "analogous to `models`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "measures()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4. Evaluate the model performance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naturally, MLJ provides boilerplate code for carrying out a model\n",
    "evaluation with a lot less fuss. Let's repeat the performance\n",
    "evaluation above and add an extra measure, `brier_score`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=Holdout(fraction_train=0.7),\n",
    "          measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or applying cross-validation instead:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=CV(nfolds=6),\n",
    "          measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, Monte Carlo cross-validation (cross-validation repeated\n",
    "randomized folds)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "e = evaluate!(mach, resampling=CV(nfolds=6, rng=123),\n",
    "              repeats=3,\n",
    "              measures=[cross_entropy, brier_score])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "One can access the following properties of the output `e` of an\n",
    "evaluation: `measure`, `measurement`, `per_fold` (measurement for\n",
    "each fold) and `per_observation` (measurement per observation, if\n",
    "reported)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally note that you can restrict the rows of observations from\n",
    "which train and test folds are drawn, by specifying `rows=...`. For\n",
    "example, imagining the last 30% of target observations are `missing`\n",
    "you might have a work-flow like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train, test = partition(eachindex(y), 0.7)\n",
    "mach = machine(model, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6),\n",
    "          measures=[cross_entropy, brier_score],\n",
    "          rows=train)     # cv estimate, resampling from `train`\n",
    "fit!(mach, rows=train)    # re-train using all of `train` observations\n",
    "predict(mach, rows=test); # and predict missing targets"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On learning curves"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since our model is an iterative one, we might want to inspect the\n",
    "out-of-sample performance as a function of the iteration\n",
    "parameter. For this we can use the `learning_curve` function (which,\n",
    "incidentally can be applied to any model hyper-parameter). This\n",
    "starts by defining a one-dimensional range object for the parameter\n",
    "(more on this when we discuss tuning in Part 4):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(model, :epochs, lower=1, upper=50, scale=:log)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=Holdout(fraction_train=0.7), # (default)\n",
    "                       measure=cross_entropy)\n",
    "\n",
    "using Plots\n",
    "gr(size=(490,300))\n",
    "plt=plot(curve.parameter_values, curve.measurements)\n",
    "xlabel!(plt, \"epochs\")\n",
    "ylabel!(plt, \"cross entropy on holdout set\")\n",
    "savefig(\"learning_curve.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will return to learning curves when we look at tuning in Part 4."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- From the MLJ manual:\n",
    "    - [Getting Started](https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/)\n",
    "    - [Model Search](https://alan-turing-institute.github.io/MLJ.jl/dev/model_search/)\n",
    "    - [Evaluating Performance](https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/) (using `evaluate!`)\n",
    "    - [Learning Curves](https://alan-turing-institute.github.io/MLJ.jl/dev/learning_curves/)\n",
    "    - [Performance Measures](https://alan-turing-institute.github.io/MLJ.jl/dev/performance_measures/) (loss functions, scores, etc)\n",
    "- From Data Science Tutorials:\n",
    "    - [Choosing and evaluating a model](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/choosing-a-model/)\n",
    "    - [Fit, predict, transform](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/fit-and-predict/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Identify all supervised MLJ models that can be applied (without\n",
    "type coercion or one-hot encoding) to a supervised learning problem\n",
    "with input features `X4` and target `y4` defined below:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Distributions\n",
    "poisson = Distributions.Poisson\n",
    "\n",
    "age = 18 .+ 60*rand(10);\n",
    "salary = coerce(rand([\"small\", \"big\", \"huge\"], 10), OrderedFactor);\n",
    "levels!(salary, [\"small\", \"big\", \"huge\"]);\n",
    "small = CategoricalValue(\"small\", salary)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X4 = DataFrames.DataFrame(age=age, salary=salary)\n",
    "\n",
    "n_devices(salary) = salary > small ? rand(poisson(1.3)) : rand(poisson(2.9))\n",
    "y4 = [n_devices(row.salary) for row in eachrow(X4)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) What models can be applied if you coerce the salary to a\n",
    "`Continuous` scitype?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 5 (unpack)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After evaluating the following ..."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = (a = [1, 2, 3, 4],\n",
    "        b = rand(4),\n",
    "        c = rand(4),\n",
    "        d = coerce([\"male\", \"female\", \"female\", \"male\"], OrderedFactor));\n",
    "pretty(data)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Tables\n",
    "y, X, w = unpack(data,\n",
    "                 ==(:a),\n",
    "                 name -> elscitype(Tables.getcolumn(data, name)) == Continuous,\n",
    "                 name -> true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "...attempt to guess the evaluations of the following:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pretty(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "w"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 6 (first steps in modeling Horse Colic)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Suppose we want to use predict the `:outcome` variable in the\n",
    "Horse Colic study introduced in Part 1, based on the remaining\n",
    "variables that are `Continuous` (one-hot encoding categorical\n",
    "variables is discussed later in Part 3) *while ignoring the others*.\n",
    "Extract from the `horse` data set (defined in Part 1) appropriate\n",
    "input features `X` and target variable `y`. (Do not, however,\n",
    "randomize the observations.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Create a 70:30 `train`/`test` split of the data and train a\n",
    "`LogisticClassifier` model, from the `MLJLinearModels` package, on\n",
    "the `train` rows. Use `lambda=100` and default values for the\n",
    "other hyper-parameters. (Although one would normally standardize\n",
    "(whiten) the continuous features for this model, do not do so here.)\n",
    "After training:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (i) Recalling that a logistic classifier (aka logistic regressor) is\n",
    "  a linear-based model learning a *vector* of coefficients for each\n",
    "  feature (one coefficient for each target class), use the\n",
    "  `fitted_params` method to find this vector of coefficients in the\n",
    "  case of the `:pulse` feature. (You can convert a vector of pairs `v =\n",
    "  [x1 => y1, x2 => y2, ...]` into a dictionary with `Dict(v)`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (ii) Evaluate the `cross_entropy` performance on the `test`\n",
    "  observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- &star;(iii) In how many `test` observations does the predicted\n",
    "  probability of the observed class exceed 50%?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (iv) Find the `misclassification_rate` in the `test`\n",
    "  set. (*Hint.* As this measure is deterministic, you will either\n",
    "  need to broadcast `mode` or use `predict_mode` instead of\n",
    "  `predict`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) Instead use a `RandomForestClassifier` model from the\n",
    "    `DecisionTree` package and:\n",
    "\n",
    "- (i) Generate an appropriate learning curve to convince yourself\n",
    "  that out-of-sample estimates of the `cross_entropy` loss do not\n",
    "  substantially improve for `n_trees > 50`. Use default values for\n",
    "  all other hyper-parameters, and feel free to use all available\n",
    "  data to generate the curve."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (ii) Fix `n_trees=90` and use `evaluate!` to obtain a 9-fold\n",
    "  cross-validation estimate of the `cross_entropy`, restricting\n",
    "  sub-sampling to the `train` observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- (iii) Now use *all* available data but set\n",
    "  `resampling=Holdout(fraction_train=0.7)` to obtain a score you can\n",
    "  compare with the `KNNClassifier` in part (b)(iii). Which model is\n",
    "  better?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part-3-transformers-and-pipelines'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3 - Transformers and Pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unsupervised models, which receive no target `y` during training,\n",
    "always have a `transform` operation. They sometimes also support an\n",
    "`inverse_transform` operation, with obvious meaning, and sometimes\n",
    "support a `predict` operation (see the clustering example discussed\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#Transformers-that-also-predict-1)).\n",
    "Otherwise, they are handled much like supervised models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a simple standardization example:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x = rand(100);\n",
    "@show mean(x) std(x);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = Standardizer() # a built-in model\n",
    "mach = machine(model, x)\n",
    "fit!(mach)\n",
    "xhat = transform(mach, x);\n",
    "@show mean(xhat) std(xhat);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This particular model has an `inverse_transform`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "inverse_transform(mach, xhat) ≈ x"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Re-encoding the King County House data as continuous"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For further illustrations of transformers, let's re-encode *all* of the\n",
    "King County House input features (see [Ex\n",
    "3](#exercise-3-fixing-scitypes-in-a-table)) into a set of `Continuous`\n",
    "features. We do this with the `ContinuousEncoder` model, which, by\n",
    "default, will:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- one-hot encode all `Multiclass` features\n",
    "- coerce all `OrderedFactor` features to `Continuous` ones\n",
    "- coerce all `Count` features to `Continuous` ones (there aren't any)\n",
    "- drop any remaining non-Continuous features (none of these either)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we reload the data and fix the scitypes (Exercise 3):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "file = CSV.File(joinpath(DIR, \"data\", \"house.csv\"));\n",
    "house = DataFrames.DataFrame(file);\n",
    "coerce!(house, autotype(file));\n",
    "coerce!(house, Count => Continuous, :zipcode => Multiclass);\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(house, ==(:price), name -> true, rng=123);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate the unsupervised model (transformer):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "encoder = ContinuousEncoder() # a built-in model; no need to @load it"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bind the model to the data and fit!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(encoder, X) |> fit!;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform and inspect the result:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xcont = transform(mach, X);\n",
    "schema(Xcont)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### More transformers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's how to list all of MLJ's unsupervised models:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(m->!m.is_supervised)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some commonly used ones are built-in (do not require `@load`ing):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "model type                  | does what?\n",
    "----------------------------|----------------------------------------------\n",
    "ContinuousEncoder | transform input table to a table of `Continuous` features (see above)\n",
    "FeatureSelector | retain or dump selected features\n",
    "FillImputer | impute missing values\n",
    "OneHotEncoder | one-hot encoder `Multiclass` (and optionally `OrderedFactor`) features\n",
    "Standardizer | standardize (whiten) a vector or all `Continuous` features of a table\n",
    "UnivariateBoxCoxTransformer | apply a learned Box-Cox transformation to a vector\n",
    "UnivariateDiscretizer | discretize a `Continuous` vector, and hence render its elscitypw `OrderedFactor`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to \"dynamic\" transformers (ones that learn something\n",
    "from the data and must be `fit!`) users can wrap ordinary functions\n",
    "as transformers, and such *static* transformers can depend on\n",
    "parameters, like the dynamic ones. See\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#Static-transformers-1)\n",
    "for how to define your own static transformers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipelines"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "length(schema(Xcont).names)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's suppose that additionally we'd like to reduce the dimension of\n",
    "our data.  A model that will do this is `PCA` from\n",
    "`MultivariateStats`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "PCA = @load PCA\n",
    "reducer = PCA()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, rather simply repeating the work-flow above, applying the new\n",
    "transformation to `Xcont`, we can combine both the encoding and the\n",
    "dimension-reducing models into a single model, known as a\n",
    "*pipeline*. While MLJ offers a powerful interface for composing\n",
    "models in a variety of ways, we'll stick to these simplest class of\n",
    "composite models for now. The easiest way to construct them is using\n",
    "the `@pipeline` macro:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe = @pipeline encoder reducer"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that `pipe` is an *instance* of an automatically generated\n",
    "type (called `Pipeline<some digits>`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The new model behaves like any other transformer:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe, X)\n",
    "fit!(mach)\n",
    "Xsmall = transform(mach, X)\n",
    "schema(Xsmall)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Want to combine this pre-processing with ridge regression?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "RidgeRegressor = @load RidgeRegressor pkg=MLJLinearModels\n",
    "rgs = RidgeRegressor()\n",
    "pipe2 = @pipeline encoder reducer rgs"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our pipeline is a supervised model, instead of a transformer,\n",
    "whose performance we can evaluate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe2, X, y)\n",
    "evaluate!(mach, measure=mae, resampling=Holdout()) # CV(nfolds=6) is default"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training of composite models is \"smart\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now notice what happens if we train on all the data, then change a\n",
    "regressor hyper-parameter and retrain:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe2.ridge_regressor.lambda = 0.1\n",
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second time only the ridge regressor is retrained!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mutate a hyper-parameter of the `PCA` model and every model except\n",
    "the `ContinuousEncoder` (which comes before it will be retrained):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe2.pca.pratio = 0.9999\n",
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspecting composite models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dot syntax used above to change the values of *nested*\n",
    "hyper-parameters is also useful when inspecting the learned\n",
    "parameters and report generated when training a composite model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fitted_params(mach).ridge_regressor"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "report(mach).pca"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Incorporating target transformations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, suppose that instead of using the raw `:price` as the\n",
    "training target, we want to use the log-price (a common practice in\n",
    "dealing with house price data). However, suppose that we still want\n",
    "to report final *predictions* on the original linear scale (and use\n",
    "these for evaluation purposes). Then we supply appropriate functions\n",
    "to key-word arguments `target` and `inverse`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we'll overload `log` and `exp` for broadcasting:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Base.log(v::AbstractArray) = log.(v)\n",
    "Base.exp(v::AbstractArray) = exp.(v)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the new pipeline:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe3 = @pipeline encoder reducer rgs target=log inverse=exp\n",
    "mach = machine(pipe3, X, y)\n",
    "evaluate!(mach, measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLJ will also allow you to insert *learned* target\n",
    "transformations. For example, we might want to apply\n",
    "`Standardizer()` to the target, to standardize it, or\n",
    "`UnivariateBoxCoxTransformer()` to make it look Gaussian. Then\n",
    "instead of specifying a *function* for `target`, we specify a\n",
    "unsupervised *model* (or model type). One does not specify `inverse`\n",
    "because only models implementing `inverse_transform` are\n",
    "allowed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see which of these two options results in a better outcome:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "box = UnivariateBoxCoxTransformer(n=20)\n",
    "stand = Standardizer()\n",
    "\n",
    "pipe4 = @pipeline encoder reducer rgs target=box\n",
    "mach = machine(pipe4, X, y)\n",
    "evaluate!(mach, measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe4.target = stand\n",
    "evaluate!(mach, measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- From the MLJ manual:\n",
    "    - [Transformers and other unsupervised models](https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/)\n",
    "    - [Linear pipelines](https://alan-turing-institute.github.io/MLJ.jl/dev/linear_pipelines/#Linear-Pipelines)\n",
    "- From Data Science Tutorials:\n",
    "    - [Composing models](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/composing-models/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Consider again the Horse Colic classification problem considered in\n",
    "Exercise 6, but with all features, `Finite` and `Infinite`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(horse, ==(:outcome), name -> true);\n",
    "schema(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Define a pipeline that:\n",
    "- uses `Standardizer` to ensure that features that are already\n",
    "  continuous are centered at zero and have unit variance\n",
    "- re-encodes the full set of features as `Continuous`, using\n",
    "  `ContinuousEncoder`\n",
    "- uses the `KMeans` clustering model from `Clustering.jl`\n",
    "  to reduce the dimension of the feature space to `k=10`.\n",
    "- trains a `EvoTreeClassifier` (a gradient tree boosting\n",
    "  algorithm in `EvoTrees.jl`) on the reduced data, using\n",
    "  `nrounds=50` and default values for the other\n",
    "   hyper-parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Evaluate the pipeline on all data, using 6-fold cross-validation\n",
    "and `cross_entropy` loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "&star;(c) Plot a learning curve which examines the effect on this loss\n",
    "as the tree booster parameter `max_depth` varies from 2 to 10."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part-4-tuning-hyper-parameters'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4 - Tuning Hyper-parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive tuning of a single parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most naive way to tune a single hyper-parameter is to use\n",
    "`learning_curve`, which we already saw in Part 2. Let's see this in\n",
    "the Horse Colic classification problem, in a case where the parameter\n",
    "to be tuned is *nested* (because the model is a pipeline):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(horse, ==(:outcome), name -> true);\n",
    "\n",
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels\n",
    "model = @pipeline Standardizer ContinuousEncoder LogisticClassifier\n",
    "mach = machine(model, X, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(model, :(logistic_classifier.lambda), lower = 1e-2, upper=100, scale=:log10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you're curious, you can see what `lambda` values this range will\n",
    "generate for a given resolution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "iterator(r, 5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "_, _, lambdas, losses = learning_curve(mach,\n",
    "                                       range=r,\n",
    "                                       resampling=CV(nfolds=6),\n",
    "                                       resolution=30, # default\n",
    "                                       measure=cross_entropy)\n",
    "plt=plot(lambdas, losses, xscale=:log10)\n",
    "xlabel!(plt, \"lambda\")\n",
    "ylabel!(plt, \"cross entropy using 6-fold CV\")\n",
    "savefig(\"learning_curve2.png\")\n",
    "plt\n",
    "\n",
    "\n",
    "best_lambda = lambdas[argmin(losses)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self tuning models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A more sophisticated way to view hyper-parameter tuning (inspired by\n",
    "MLR) is as a model *wrapper*. The wrapped model is a new model in\n",
    "its own right and when you fit it, it tunes specified\n",
    "hyper-parameters of the model being wrapped, before training on all\n",
    "supplied data. Calling `predict` on the wrapped model is like\n",
    "calling `predict` on the original model, but with the\n",
    "hyper-parameters already optimized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In other words, we can think of the wrapped model as a \"self-tuning\"\n",
    "version of the original."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now create a self-tuning version of the pipeline above, adding a\n",
    "parameter from the `ContinuousEncoder` to the parameters we want\n",
    "optimized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's choose a tuning strategy (from [these\n",
    "options](https://github.com/juliaai/MLJTuning.jl#what-is-provided-here)). MLJ\n",
    "supports ordinary `Grid` search (query `?Grid` for\n",
    "details). However, as the utility of `Grid` search is limited to a\n",
    "small number of parameters, and as `Grid` searches are demonstrated\n",
    "elsewhere (see the [resources below](#resources-for-part-4)) we'll\n",
    "demonstrate `RandomSearch` here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuning = RandomSearch(rng=123)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this strategy each parameter is sampled according to a\n",
    "pre-specified prior distribution that is fit to the one-dimensional\n",
    "range object constructed using `range` as before. While one has a\n",
    "lot of control over the specification of the priors (run\n",
    "`?RandomSearch` for details) we'll let the algorithm generate these\n",
    "priors automatically."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Unbounded ranges and sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ a range does not have to be bounded. In a `RandomSearch` a\n",
    "positive unbounded range is sampled using a `Gamma` distribution, by\n",
    "default:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(model,\n",
    "          :(logistic_classifier.lambda),\n",
    "          lower=0,\n",
    "          origin=6,\n",
    "          unit=5,\n",
    "          scale=:log10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `scale` in a range makes no in a `RandomSearch` (unless it is a\n",
    "function) but this will effect later plots but it does effect the\n",
    "later plots."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what sampling using a Gamma distribution is going to mean\n",
    "for this range:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Distributions\n",
    "sampler_r = sampler(r, Distributions.Gamma)\n",
    "plt = histogram(rand(sampler_r, 10000), nbins=50)\n",
    "savefig(\"gamma_sampler.png\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](gamma_sampler.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second parameter that we'll add to this is *nominal* (finite) and, by\n",
    "default, will be sampled uniformly. Since it is nominal, we specify\n",
    "`values` instead of `upper` and `lower` bounds:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "s  = range(model, :(continuous_encoder.one_hot_ordered_factors),\n",
    "           values = [true, false])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The tuning wrapper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now for the wrapper, which is an instance of `TunedModel`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_model = TunedModel(model=model,\n",
    "                         ranges=[r, s],\n",
    "                         resampling=CV(nfolds=6),\n",
    "                         measures=cross_entropy,\n",
    "                         tuning=tuning,\n",
    "                         n=15)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can apply the `fit!/predict` work-flow to `tuned_model` just as\n",
    "for any other model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_mach = machine(tuned_model, X, y);\n",
    "fit!(tuned_mach);\n",
    "predict(tuned_mach, rows=1:3)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The outcomes of the tuning can be inspected from a detailed\n",
    "report. For example, we have:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "rep = report(tuned_mach);\n",
    "rep.best_model"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, sampling of a bounded range is uniform. Lets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the special case of two-parameters, you can also plot the results:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = plot(tuned_mach)\n",
    "savefig(\"tuning.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's compare cross-validation estimate of the performance\n",
    "of the self-tuning model with that of the original model (an example\n",
    "of [*nested\n",
    "resampling*]((https://mlr.mlr-org.com/articles/tutorial/nested_resampling.html)\n",
    "here):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "err = evaluate!(mach, resampling=CV(nfolds=3), measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_err = evaluate!(tuned_mach, resampling=CV(nfolds=3), measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='resources-for-part-4'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 4\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [Learning Curves](https://alan-turing-institute.github.io/MLJ.jl/dev/learning_curves/)\n",
    "   - [Tuning Models](https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/)\n",
    "- The [MLJTuning repo](https://github.com/juliaai/MLJTuning.jl#who-is-this-repo-for) - mostly for developers\n",
    "\n",
    "- From Data Science Tutorials:\n",
    "    - [Tuning a model](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/model-tuning/)\n",
    "    - [Crabs with XGBoost](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/crabs-xgb/) `Grid` tuning in stages for a tree-boosting model with many parameters\n",
    "    - [Boston with LightGBM](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/boston-lgbm/) -  `Grid` tuning for another popular tree-booster\n",
    "    - [Boston with Flux](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/boston-flux/) - optimizing batch size in a simple neural network regressor\n",
    "- [UCI Horse Colic Data Set](http://archive.ics.uci.edu/ml/datasets/Horse+Colic)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercises for Part 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This exercise continues our analysis of the King County House price\n",
    "prediction problem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(house, ==(:price), name -> true, rng=123);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your task will be to tune the following pipeline regression model,\n",
    "which includes a gradient tree boosting component:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "EvoTreeRegressor = @load EvoTreeRegressor\n",
    "tree_booster = EvoTreeRegressor(nrounds = 70)\n",
    "model = @pipeline ContinuousEncoder tree_booster"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Construct a bounded range `r1` for the `evo_tree_booster`\n",
    "parameter `max_depth`, varying between 1 and 12."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\\star&(b) For the `nbins` parameter of the `EvoTreeRegressor`, define the range"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r2 = range(model,\n",
    "           :(evo_tree_regressor.nbins),\n",
    "           lower = 2.5,\n",
    "           upper= 7.5, scale=x->2^round(Int, x))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that in this case we've specified a *function* instead of a\n",
    "canned scale, like `:log10`. In this case the `scale` function is\n",
    "applied after sampling (uniformly) between the limits of `lower` and\n",
    "`upper`. Perhaps you can guess the outputs of the following lines of\n",
    "code?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r2_sampler = sampler(r2, Distributions.Uniform)\n",
    "samples = rand(r2_sampler, 1000);\n",
    "histogram(samples, nbins=50)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sort(unique(samples))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) Optimize `model` over these the parameter ranges `r1` and `r2`\n",
    "using a random search with uniform priors (the default). Use\n",
    "`Holdout()` resampling, and implement your search by first\n",
    "constructing a \"self-tuning\" wrap of `model`, as described\n",
    "above. Make `mae` (mean absolute error) the loss function that you\n",
    "optimize, and search over a total of 40 combinations of\n",
    "hyper-parameters.  If you have time, plot the results of your\n",
    "search. Feel free to use all available data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d) Evaluate the best model found in the search using 3-fold\n",
    "cross-validation and compare with that of the self-tuning model\n",
    "(which is different!). Setting data hygiene concerns aside, feel\n",
    "free to use all available data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part-5-advanced-model-composition'>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5 - Advanced Model Composition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Goals:**\n",
    "> 1. Learn how to build a prototypes of a composite model, called a *learning network*\n",
    "> 2. Learn how to use the `@from_network` macro to export a learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While `@pipeline` is great for composing models in an unbranching\n",
    "sequence, for more complicated model composition you'll want to use\n",
    "MLJ's generic model composition syntax. There are two main steps:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Prototype** the composite model by building a *learning\n",
    "  network*, which can be tested on some (dummy) data as you build\n",
    "  it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Export** the learning network as a new stand-alone model type."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like pipeline models, instances of the exported model type behave\n",
    "like any other model (and are not bound to any data, until you wrap\n",
    "them in a machine)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a pipeline using the generic composition syntax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To warm up, we'll do the equivalent of"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe = @pipeline Standardizer LogisticClassifier;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "using the generic syntax."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's some dummy data we'll be using to test our learning network:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = make_blobs(5, 3)\n",
    "pretty(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 0** - Proceed as if you were combining the models \"by hand\",\n",
    "using all the data available for training, transforming and\n",
    "prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "fit!(mach1);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "fit!(mach2);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 1** - Edit your code as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- pre-wrap the data in `Source` nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- delete the `fit!` calls"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = source(X)  # or X = source() if not testing\n",
    "y = source(y)  # or y = source()\n",
    "\n",
    "stand = Standardizer();\n",
    "linear = LogisticClassifier();\n",
    "\n",
    "mach1 = machine(stand, X);\n",
    "Xstand = transform(mach1, X);\n",
    "\n",
    "mach2 = machine(linear, Xstand, y);\n",
    "yhat = predict(mach2, Xstand)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `X`, `y`, `Xstand` and `yhat` are *nodes* (\"variables\" or\n",
    "\"dynammic data\") instead of data. All training, predicting and\n",
    "transforming is now executed lazily, whenever we `fit!` one of these\n",
    "nodes. We *call* a node to retrieve the data it represents in the\n",
    "original manual workflow."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(Xstand)\n",
    "Xstand() |> pretty"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(yhat);\n",
    "yhat()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The node `yhat` is the \"descendant\" (in an associated DAG we have\n",
    "defined) of a unique source node:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sources(yhat)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data at the source node is replaced by `Xnew` to obtain a\n",
    "new prediction when we call `yhat` like this:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3);\n",
    "yhat(Xnew)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2** - Export the learning network as a new stand-alone model type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, somewhat paradoxically, we can wrap the whole network in a\n",
    "special machine - called a *learning network machine* - before have\n",
    "defined the new model type. Indeed doing so is a necessary step in\n",
    "the export process, for this machine will tell the export macro:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- what kind of model the composite will be (`Deterministic`,\n",
    "  `Probabilistic` or `Unsupervised`)a"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which source nodes are input nodes and which are for the target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- which nodes correspond to each operation (`predict`, `transform`,\n",
    "  etc) that we might want to define"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "surrogate = Probabilistic()     # a model with no fields!\n",
    "mach = machine(surrogate, X, y; predict=yhat)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although we have no real need to use it, this machine behaves like\n",
    "you'd expect it to:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Xnew, _ = make_blobs(2, 3)\n",
    "fit!(mach)\n",
    "predict(mach, Xnew)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create a new model type using a Julia `struct` definition\n",
    "appropriately decorated:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network mach begin\n",
    "    mutable struct YourPipe\n",
    "        standardizer = stand\n",
    "        classifier = linear::Probabilistic\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiating and evaluating on some new data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe = YourPipe()\n",
    "X, y = @load_iris;   # built-in data set\n",
    "mach = machine(pipe, X, y)\n",
    "evaluate!(mach, measure=misclassification_rate, operation=predict_mode)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A composite model to average two regressor predictors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is condensed version of\n",
    "[this](https://github.com/alan-turing-institute/MLJ.jl/blob/master/binder/MLJ_demo.ipynb)\n",
    "tutorial. We will define a composite model that:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- standardizes the input data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- learns and applies a Box-Cox transformation to the target variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- blends the predictions of two supervised learning models - a ridge\n",
    " regressor and a random forest regressor; we'll blend using a simple\n",
    " average (for a more sophisticated stacking example, see\n",
    " [here](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- applies the *inverse* Box-Cox transformation to this blended prediction"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "RandomForestRegressor = @load RandomForestRegressor pkg=DecisionTree"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Input layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = source()\n",
    "y = source()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First layer and target transformation**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "std_model = Standardizer()\n",
    "stand = machine(std_model, X)\n",
    "W = MLJ.transform(stand, X)\n",
    "\n",
    "box_model = UnivariateBoxCoxTransformer()\n",
    "box = machine(box_model, y)\n",
    "z = MLJ.transform(box, y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Second layer**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ridge_model = RidgeRegressor(lambda=0.1)\n",
    "ridge = machine(ridge_model, W, z)\n",
    "\n",
    "forest_model = RandomForestRegressor(n_trees=50)\n",
    "forest = machine(forest_model, W, z)\n",
    "\n",
    "ẑ = 0.5*predict(ridge, W) + 0.5*predict(forest, W)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Output**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ŷ = inverse_transform(box, ẑ)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the learning network defined, we're ready to export:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@from_network machine(Deterministic(), X, y, predict=ŷ) begin\n",
    "    mutable struct CompositeModel\n",
    "        rgs1 = ridge_model\n",
    "        rgs2 = forest_model\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's instantiate the new model type and try it out on some data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "composite = CompositeModel()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = @load_boston;\n",
    "mach = machine(composite, X, y);\n",
    "evaluate!(mach,\n",
    "          resampling=CV(nfolds=6, shuffle=true),\n",
    "          measures=[rms, mae])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resources for Part 5\n",
    "\n",
    "- From the MLJ manual:\n",
    "   - [Learning Networks](https://alan-turing-institute.github.io/MLJ.jl/stable/composing_models/#Learning-Networks-1)\n",
    "- From Data Science Tutorials:\n",
    "    - [Learning Networks](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks/)\n",
    "    - [Learning Networks 2](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/learning-networks-2/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    - [Stacking](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/stacking/): an advanced example of model composition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    - [Finer Control](https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Method-II:-Finer-control-(advanced)-1):\n",
    "      exporting learning networks without a macro for finer control"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='solutions-to-exercises'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solutions to exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 2 solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "quality = coerce(quality, OrderedFactor);\n",
    "levels!(quality, [\"poor\", \"good\", \"excellent\"]);\n",
    "elscitype(quality)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 3 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First pass:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, autotype(house));\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the \"sqft\" fields refer to \"square feet\" so are\n",
    "really `Continuous`. We'll regard `:yr_built` (the other `Count`\n",
    "variable above) as `Continuous` as well. So:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, Count => Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And `:zipcode` should not be ordered:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coerce!(house, :zipcode => Multiclass);\n",
    "schema(house)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`:bathrooms` looks like it has a lot of levels, but on further\n",
    "inspection we see why, and `OrderedFactor` remains appropriate:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import StatsBase.countmap\n",
    "countmap(house.bathrooms)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 4 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are *no* models that apply immediately:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4(b)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y4 = coerce(y4, Continuous);\n",
    "models(matching(X4, y4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 6 solution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(horse,\n",
    "              ==(:outcome),\n",
    "              name -> elscitype(Tables.getcolumn(horse, name)) == Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = (@load LogisticClassifier pkg=MLJLinearModels)();\n",
    "model.lambda = 100\n",
    "mach = machine(model, X, y)\n",
    "fit!(mach, rows=train)\n",
    "fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "coefs_given_feature = Dict(fitted_params(mach).coefs)\n",
    "coefs_given_feature[:pulse]\n",
    "\n",
    "#6(b)(ii)\n",
    "\n",
    "yhat = predict(mach, rows=test); # or predict(mach, X[test,:])\n",
    "err = cross_entropy(yhat, y[test]) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iii)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted probabilities of the actual observations in the test\n",
    "are given by"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = broadcast(pdf, yhat, y[test]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of times this probability exceeds 50% is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n50 = filter(x -> x > 0.5, p) |> length"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, as a proportion:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n50/length(test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(b)(iv)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "misclassification_rate(mode.(yhat), y[test])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(i)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = (@load RandomForestClassifier pkg=DecisionTree)()\n",
    "mach = machine(model, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6), measure=cross_entropy)\n",
    "\n",
    "r = range(model, :n_trees, lower=10, upper=70, scale=:log10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since random forests are inherently randomized, we generate multiple\n",
    "curves:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = plot()\n",
    "for i in 1:4\n",
    "    one_curve = learning_curve(mach,\n",
    "                           range=r,\n",
    "                           resampling=Holdout(),\n",
    "                           measure=cross_entropy)\n",
    "    plot!(one_curve.parameter_values, one_curve.measurements)\n",
    "end\n",
    "xlabel!(plt, \"n_trees\")\n",
    "ylabel!(plt, \"cross entropy\")\n",
    "savefig(\"exercise_6ci.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(ii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "evaluate!(mach, resampling=CV(nfolds=9),\n",
    "                measure=cross_entropy,\n",
    "                rows=train).measurement[1]\n",
    "\n",
    "model.n_trees = 90"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "6(c)(iii)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "err_forest = evaluate!(mach, resampling=Holdout(),\n",
    "                       measure=cross_entropy).measurement[1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "KMeans = @load KMeans pkg=Clustering\n",
    "EvoTreeClassifier = @load EvoTreeClassifier\n",
    "pipe = @pipeline(Standardizer,\n",
    "                 ContinuousEncoder,\n",
    "                 KMeans(k=10),\n",
    "                 EvoTreeClassifier(nrounds=50))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe, X, y)\n",
    "evaluate!(mach, resampling=CV(nfolds=6), measure=cross_entropy)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = range(pipe, :(evo_tree_classifier.max_depth), lower=1, upper=10)\n",
    "\n",
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=CV(nfolds=6),\n",
    "                       measure=cross_entropy)\n",
    "\n",
    "plt = plot(curve.parameter_values, curve.measurements)\n",
    "xlabel!(plt, \"max_depth\")\n",
    "ylabel!(plt, \"CV estimate of cross entropy\")\n",
    "savefig(\"exercise_7c.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a second curve using a different random seed for the booster:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Random\n",
    "pipe.evo_tree_classifier.rng = MersenneTwister(123)\n",
    "curve = learning_curve(mach,\n",
    "                       range=r,\n",
    "                       resampling=CV(nfolds=6),\n",
    "                       measure=cross_entropy)\n",
    "plot!(curve.parameter_values, curve.measurements)\n",
    "savefig(\"exercise_7c_2.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "One can automatic the production of multiple curves with different\n",
    "seeds in the following way:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "curves = learning_curve(mach,\n",
    "                        range=r,\n",
    "                        resampling=CV(nfolds=6),\n",
    "                        measure=cross_entropy,\n",
    "                        rng_name=:(evo_tree_classifier.rng),\n",
    "                        rngs=6) # list of RNGs, or num to auto generate\n",
    "plt = plot(curves.parameter_values, curves.measurements)\n",
    "savefig(\"exercise_7c_3.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have multiple threads available in your julia session, you\n",
    "can add the option `acceleration=CPUThreads()` to speed up this\n",
    "computation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exercise 8"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(house, ==(:price), name -> true, rng=123);\n",
    "\n",
    "EvoTreeRegressor = @load EvoTreeRegressor\n",
    "tree_booster = EvoTreeRegressor(nrounds = 70)\n",
    "model = @pipeline ContinuousEncoder tree_booster"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r1 = range(model, :(evo_tree_regressor.max_depth), lower=1, upper=12)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_model = TunedModel(model=model,\n",
    "                         ranges=[r1, r2],\n",
    "                         resampling=Holdout(),\n",
    "                         measures=mae,\n",
    "                         tuning=RandomSearch(rng=123),\n",
    "                         n=40)\n",
    "\n",
    "tuned_mach = machine(tuned_model, X, y) |> fit!\n",
    "plt = plot(tuned_mach)\n",
    "savefig(\"exercise_8c.png\")\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "(d)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "best_model = report(tuned_mach).best_model;\n",
    "best_mach = machine(best_model, X, y);\n",
    "best_err = evaluate!(best_mach, resampling=CV(nfolds=3), measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_err = evaluate!(tuned_mach, resampling=CV(nfolds=3), measure=mae)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
